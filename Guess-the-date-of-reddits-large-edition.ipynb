{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Guess the date of reddits.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdaT5zz7YJrt"
      },
      "source": [
        "**Guess the date of reddits (large edition)**\r\n",
        "\r\n",
        "**Task**: Guess a reddit date based on its text. This is larger version with more reddits and subrredits (topics)\r\n",
        "\r\n",
        "*Adam Mickiewicz University*\r\n",
        "\r\n",
        "*Faculty of Mathematics and Computer Science*\r\n",
        "\r\n",
        "*Subject: Machine translation*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPex7z7LxBOK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "780facd1-f686-4758-c899-0ae9b8ec19b7"
      },
      "source": [
        "!git clone https://git.wmi.amu.edu.pl/dawjur/guess-reddit-date-sumo.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'guess-reddit-date-sumo'...\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 20 (delta 2), reused 0 (delta 0)\n",
            "Unpacking objects: 100% (20/20), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIrp9C0pnbpL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91f13648-67c0-4838-c04d-cb4a3d54cb73"
      },
      "source": [
        "!xzcat \"guess-reddit-date-sumo/train/in.tsv.xz\" | wc -l"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHseHmcnw_2N"
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import sklearn.metrics\n",
        "import sklearn.decomposition\n",
        "import sklearn.feature_extraction.text\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import csv\n",
        "import datetime\n",
        "import lzma\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOS5P-jj6LaG"
      },
      "source": [
        "def read_file_to_list(path):\n",
        "  row_list = []\n",
        "  with lzma.open(path) as fp:\n",
        "    while True:\n",
        "      line = fp.readline() \n",
        "      if not line:\n",
        "        break\n",
        "      row_list.append(line)\n",
        "  return row_list"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TljBMFRtxDO_"
      },
      "source": [
        "def load_set(path, isTest):\n",
        "  dataset = pd.DataFrame(read_file_to_list(\"guess-reddit-date-sumo/\"+path+\"/in.tsv.xz\"),columns=[\"text\"])\n",
        "  if not isTest:\n",
        "    expected = pd.read_csv(\"guess-reddit-date-sumo/\"+path+\"/expected.tsv.xz\",header=None,names=[\"year\"])\n",
        "    return dataset, expected\n",
        "  return dataset"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PKA_qCfxEpC"
      },
      "source": [
        "train_set, expected_train = load_set(\"train\", False)\n",
        "dev_set, expected_dev = load_set(\"dev-0\", False)\n",
        "test_set = load_set(\"test-A\", True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYDpF7bIqvR1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd7f5478-5361-46a0-a8c4-6d441b9a8324"
      },
      "source": [
        "test_set.info()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   text    100000 non-null  object\n",
            "dtypes: object(1)\n",
            "memory usage: 781.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR4e-jKponUt"
      },
      "source": [
        "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(\n",
        "    stop_words='english',\n",
        "    ngram_range=(1, 1), \n",
        ")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgvX12szoqga"
      },
      "source": [
        "train_set = train_set.fillna(\"No text\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B22IQoP4pTUl"
      },
      "source": [
        "train_data = vectorizer.fit_transform(train_set[\"text\"])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69k7eDGjaHDU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31a02a5e-09ab-4e16-abee-99cc3925aa84"
      },
      "source": [
        "pca = sklearn.decomposition.TruncatedSVD(n_components=100)\n",
        "data = pca.fit_transform(train_data)\n",
        "data"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.01287501, -0.00295359, -0.00097173, ..., -0.00493291,\n",
              "         0.00203225,  0.00675423],\n",
              "       [ 0.11081329, -0.00849485,  0.0384299 , ..., -0.00331018,\n",
              "         0.02321383, -0.00240181],\n",
              "       [ 0.11272593, -0.01940163, -0.00712396, ..., -0.00138703,\n",
              "         0.00560076, -0.00931112],\n",
              "       ...,\n",
              "       [ 0.16472329, -0.03708477, -0.03033352, ..., -0.045385  ,\n",
              "         0.00520277,  0.02801315],\n",
              "       [ 0.01377693, -0.00300024,  0.00029046, ...,  0.03991493,\n",
              "        -0.02230031,  0.09500838],\n",
              "       [ 0.0617862 , -0.01005282, -0.00280986, ..., -0.01976292,\n",
              "        -0.02490221,  0.00413727]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sglz1hFXqEfk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dfea39b-43c7-42aa-85f9-c55351cfe7f5"
      },
      "source": [
        "regression = LinearRegression()\n",
        "regression.fit(data,expected_train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GRjBxpeJA08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca3747ad-0ead-42e6-e25c-34d1936e982f"
      },
      "source": [
        "mean_squared_error(regression.predict(data),expected_train)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.8575883487072233"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spVlkvalmAuz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "90c0e19c-9710-4534-adec-334c4c8f7b26"
      },
      "source": [
        "dev_set"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b'I love these.\\n'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b'#39!\\n'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b'Anything [here](https://www.reddit.com/r/gam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b\"Source? Not being a dick, just actually wond...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b'At least Ribery kind of has a reason to look...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>b'Why is it that in the US people are just pic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>b'5429-7980-8121\\n'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>b\"If I was a Bayern fan I'd be pumped that a p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>b\"Honestly I enjoyed it quite a lot. Despite m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>b'I have absolutely no idea! Vine?\\n'</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text\n",
              "0                                     b'I love these.\\n'\n",
              "1                                              b'#39!\\n'\n",
              "2      b'Anything [here](https://www.reddit.com/r/gam...\n",
              "3      b\"Source? Not being a dick, just actually wond...\n",
              "4      b'At least Ribery kind of has a reason to look...\n",
              "...                                                  ...\n",
              "99995  b'Why is it that in the US people are just pic...\n",
              "99996                                b'5429-7980-8121\\n'\n",
              "99997  b\"If I was a Bayern fan I'd be pumped that a p...\n",
              "99998  b\"Honestly I enjoyed it quite a lot. Despite m...\n",
              "99999              b'I have absolutely no idea! Vine?\\n'\n",
              "\n",
              "[100000 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6L3i0BjmFr0"
      },
      "source": [
        "def transform_data(raw_data):\n",
        "  raw_data = raw_data.fillna(\"No text\")\n",
        "  vector = vectorizer.transform(raw_data[\"text\"])\n",
        "  clean_data = pca.transform(vector)\n",
        "  return clean_data"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCtXQr9Mlmrw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26a9db7b-838d-4133-8a96-ffbf4027eca9"
      },
      "source": [
        "dev_transformed = transform_data(dev_set)\n",
        "predict_dev = regression.predict(dev_transformed)\n",
        "predict_dev"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2013.7801284 ],\n",
              "       [2013.69552127],\n",
              "       [2013.34242613],\n",
              "       ...,\n",
              "       [2013.67977629],\n",
              "       [2013.85753807],\n",
              "       [2013.54962279]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4udpIHTXOzO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5cb4913-1799-4541-f34e-6ed22b62b186"
      },
      "source": [
        "test_transformed = transform_data(test_set)\n",
        "predict_test = regression.predict(test_transformed)\n",
        "predict_test"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2013.68361134],\n",
              "       [2013.70100938],\n",
              "       [2013.64563541],\n",
              "       ...,\n",
              "       [2013.60782988],\n",
              "       [2013.65974392],\n",
              "       [2013.68198109]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDzHdVmHlzjt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a13e751a-989f-4f86-d041-8de42dad0924"
      },
      "source": [
        "mean_squared_error(predict_dev,expected_dev)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.882502665661785"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayADszHcWvmS"
      },
      "source": [
        "np.savetxt('guess-reddit-date-sumo/test-A/out.tsv', predict_test, '%f')\n",
        "np.savetxt('guess-reddit-date-sumo/dev-0/out.tsv', predict_dev, '%f')"
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}