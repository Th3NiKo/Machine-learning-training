{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Imports\nimport numpy as np\nimport pandas as pd\nimport re\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import f1_score, precision_score, recall_score\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.compose import ColumnTransformer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-25T13:47:11.070284Z","iopub.execute_input":"2021-09-25T13:47:11.070605Z","iopub.status.idle":"2021-09-25T13:47:11.079794Z","shell.execute_reply.started":"2021-09-25T13:47:11.070571Z","shell.execute_reply":"2021-09-25T13:47:11.078776Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"#Settings\ndataset_path = \"/kaggle/input/covid-19-nlp-text-classification/\"","metadata":{"execution":{"iopub.status.busy":"2021-09-25T12:47:02.493190Z","iopub.execute_input":"2021-09-25T12:47:02.494324Z","iopub.status.idle":"2021-09-25T12:47:02.498548Z","shell.execute_reply.started":"2021-09-25T12:47:02.494278Z","shell.execute_reply":"2021-09-25T12:47:02.497677Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#Load dataset\ntrain_dataset = pd.read_csv(dataset_path + \"Corona_NLP_train.csv\", encoding=\"ISO-8859-1\")\ntest_dataset = pd.read_csv(dataset_path + \"Corona_NLP_test.csv\", encoding=\"ISO-8859-1\")","metadata":{"execution":{"iopub.status.busy":"2021-09-25T12:47:04.029144Z","iopub.execute_input":"2021-09-25T12:47:04.030147Z","iopub.status.idle":"2021-09-25T12:47:04.360231Z","shell.execute_reply.started":"2021-09-25T12:47:04.030097Z","shell.execute_reply":"2021-09-25T12:47:04.359395Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_dataset","metadata":{"execution":{"iopub.status.busy":"2021-09-25T12:47:05.823117Z","iopub.execute_input":"2021-09-25T12:47:05.824273Z","iopub.status.idle":"2021-09-25T12:47:05.853537Z","shell.execute_reply.started":"2021-09-25T12:47:05.824210Z","shell.execute_reply":"2021-09-25T12:47:05.852498Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#I will use only tweet text for classification\ntrain_X = train_dataset[\"OriginalTweet\"]\ntrain_y = train_dataset[\"Sentiment\"]\n\ntest_X = test_dataset[\"OriginalTweet\"]\ntest_y = test_dataset[\"Sentiment\"]","metadata":{"execution":{"iopub.status.busy":"2021-09-25T12:47:12.337898Z","iopub.execute_input":"2021-09-25T12:47:12.338201Z","iopub.status.idle":"2021-09-25T12:47:12.347766Z","shell.execute_reply.started":"2021-09-25T12:47:12.338172Z","shell.execute_reply":"2021-09-25T12:47:12.346536Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#All possible values for output\nprint(set(train_y))","metadata":{"execution":{"iopub.status.busy":"2021-09-25T12:47:17.403932Z","iopub.execute_input":"2021-09-25T12:47:17.404258Z","iopub.status.idle":"2021-09-25T12:47:17.416730Z","shell.execute_reply.started":"2021-09-25T12:47:17.404229Z","shell.execute_reply":"2021-09-25T12:47:17.415635Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#For task purpose we need only Positive, Neutral and Negative, lets exchange labels to numbers\n#I will create dictionary for this\nlabel2num = { 'Positive': 2, 'Extremely Positive': 2, 'Neutral': 1, 'Extremely Negative': 0, 'Negative': 0 }\nnum2label = { 0: 'Negative', 1:'Neutral', 2:'Positive' }\n\n#Apply dict\ntrain_y = [label2num[x] for x in train_y]\ntest_y = [label2num[x] for x in test_y]","metadata":{"execution":{"iopub.status.busy":"2021-09-25T12:52:26.785845Z","iopub.execute_input":"2021-09-25T12:52:26.786191Z","iopub.status.idle":"2021-09-25T12:52:26.803765Z","shell.execute_reply.started":"2021-09-25T12:52:26.786159Z","shell.execute_reply":"2021-09-25T12:52:26.802559Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#Example tweet\nprint(train_X[4])\nprint(train_y[4])","metadata":{"execution":{"iopub.status.busy":"2021-09-25T12:56:08.082564Z","iopub.execute_input":"2021-09-25T12:56:08.082865Z","iopub.status.idle":"2021-09-25T12:56:08.089174Z","shell.execute_reply.started":"2021-09-25T12:56:08.082837Z","shell.execute_reply":"2021-09-25T12:56:08.088130Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#Sizes of train and test sets\nprint(\"Train set size: \", len(train_X))\nprint(\"Test set size: \", len(test_X))","metadata":{"execution":{"iopub.status.busy":"2021-09-25T12:53:38.612179Z","iopub.execute_input":"2021-09-25T12:53:38.612569Z","iopub.status.idle":"2021-09-25T12:53:38.620490Z","shell.execute_reply.started":"2021-09-25T12:53:38.612536Z","shell.execute_reply":"2021-09-25T12:53:38.619209Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#Lets create some preprocessing pipeline\n\n#Create custom one for various preprocessings with text \nclass PreprocessText(BaseEstimator, TransformerMixin):    \n    def fit(self, X, y = None):\n        return self\n    \n    def transform(self, X, y=None):\n        X_ = X.copy()\n        X_ = [re.sub(r'http\\S+', '', x) for x in X_] #Delete links\n        return X_\n\n#Rest will do count vectorizer (lowercase, split, stopwords)\n#Create pipeline for preprocessing\npreprocessing_pipeline = Pipeline([\n    ('delete_links', PreprocessText()),\n    ('tfidf_vectorizer', TfidfVectorizer(ngram_range=(1,1), lowercase=True, stop_words='english')),\n])","metadata":{"execution":{"iopub.status.busy":"2021-09-25T13:19:21.701953Z","iopub.execute_input":"2021-09-25T13:19:21.702505Z","iopub.status.idle":"2021-09-25T13:19:21.710159Z","shell.execute_reply.started":"2021-09-25T13:19:21.702468Z","shell.execute_reply":"2021-09-25T13:19:21.708867Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"#List of models to check\nmodels = []\nmodels.append((\"MultinomialNB\",MultinomialNB()))\nmodels.append((\"LogisticRegression\",LogisticRegression(solver='liblinear')))\nmodels.append((\"LinearSVC\", LinearSVC()))\nmodels.append((\"KNeighbors\",KNeighborsClassifier()))\nmodels.append((\"DecisionTree\",DecisionTreeClassifier()))\nmodels.append((\"RandomForest\",RandomForestClassifier()))","metadata":{"execution":{"iopub.status.busy":"2021-09-25T13:19:24.359865Z","iopub.execute_input":"2021-09-25T13:19:24.360170Z","iopub.status.idle":"2021-09-25T13:19:24.367206Z","shell.execute_reply.started":"2021-09-25T13:19:24.360137Z","shell.execute_reply":"2021-09-25T13:19:24.366356Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"#Evaluate function which prints some crucial metrics\ndef evaluate_data(predicted, true, avg=\"weighted\"):\n    print(\"Precision: \", precision_score(predicted, true, average=avg))\n    print(\"Recall: \", recall_score(predicted, true, average=avg))\n    print(\"F1: \", f1_score(predicted,true, average=avg))","metadata":{"execution":{"iopub.status.busy":"2021-09-25T13:13:37.077138Z","iopub.execute_input":"2021-09-25T13:13:37.078447Z","iopub.status.idle":"2021-09-25T13:13:37.083384Z","shell.execute_reply.started":"2021-09-25T13:13:37.078385Z","shell.execute_reply":"2021-09-25T13:13:37.082735Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"#Check diffrent models\nfor name, model in models:\n    text_preprocess_train = Pipeline([\n        ('preprocess', preprocessing_pipeline),\n        (name, model),\n    ])\n    text_preprocess_train.fit(train_X, train_y)\n    print(name)\n    print(\"Train set\")\n    evaluate_data(text_preprocess_train.predict(train_X), train_y)\n    print(\"Test set\")\n    evaluate_data(text_preprocess_train.predict(test_X), test_y)\n    print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-09-25T13:19:26.119045Z","iopub.execute_input":"2021-09-25T13:19:26.119782Z","iopub.status.idle":"2021-09-25T13:24:53.262357Z","shell.execute_reply.started":"2021-09-25T13:19:26.119729Z","shell.execute_reply":"2021-09-25T13:24:53.261065Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"#Based on models I will choose best one to tune hyperparameters with Grid Search\n#LinearSVC\nlinearsvc_params = {\n    'model__C': [0.1, 0.3, 1.0, 3.0, 10, 30, 100],\n}\nlinearcsv_pipeline = Pipeline([\n    ('preprocess', preprocessing_pipeline),\n    ('model', LinearSVC(max_iter=3000)),\n])\nlinearsvc = GridSearchCV(linearcsv_pipeline, linearsvc_params, cv=6)\nlinearsvc.fit(train_X, train_y)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T13:38:33.997831Z","iopub.execute_input":"2021-09-25T13:38:33.998159Z","iopub.status.idle":"2021-09-25T13:47:08.801795Z","shell.execute_reply.started":"2021-09-25T13:38:33.998129Z","shell.execute_reply":"2021-09-25T13:47:08.800581Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"print(linearsvc.best_params_) ","metadata":{"execution":{"iopub.status.busy":"2021-09-25T13:47:08.803936Z","iopub.execute_input":"2021-09-25T13:47:08.804527Z","iopub.status.idle":"2021-09-25T13:47:08.811973Z","shell.execute_reply.started":"2021-09-25T13:47:08.804486Z","shell.execute_reply":"2021-09-25T13:47:08.810670Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"evaluate_data(linearsvc.predict(train_X), train_y)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T13:47:08.813644Z","iopub.execute_input":"2021-09-25T13:47:08.813906Z","iopub.status.idle":"2021-09-25T13:47:10.852850Z","shell.execute_reply.started":"2021-09-25T13:47:08.813877Z","shell.execute_reply":"2021-09-25T13:47:10.851547Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"evaluate_data(linearsvc.predict(test_X), test_y)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T13:47:10.855040Z","iopub.execute_input":"2021-09-25T13:47:10.855323Z","iopub.status.idle":"2021-09-25T13:47:11.068624Z","shell.execute_reply.started":"2021-09-25T13:47:10.855292Z","shell.execute_reply":"2021-09-25T13:47:11.067348Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"#As you can see RandomForest and DecisionTree got overfitted, so it could be good idea to try it with capped depth\n#Will use randomized search because of larger number of params\nrandomforest_params = {\n    'model__n_estimators': [1, 3, 10, 30, 100, 300],\n    'model__max_depth': [6, 8, 12, 16, 20, 24],\n    'model__min_samples_split': [2, 3, 4, 5],\n    'model__min_samples_leaf': [1, 2, 3, 4],\n}\nrandomforest_pipeline = Pipeline([\n    ('preprocess', preprocessing_pipeline),\n    ('model', RandomForestClassifier()),\n])\nrandomforest = RandomizedSearchCV(randomforest_pipeline, randomforest_params, cv=6, n_iter=25)\nrandomforest.fit(train_X, train_y)\n\nprint(randomforest.best_params_) \nevaluate_data(randomforest.predict(train_X), train_y)\nevaluate_data(randomforest.predict(test_X), test_y)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T13:50:31.567892Z","iopub.execute_input":"2021-09-25T13:50:31.568258Z","iopub.status.idle":"2021-09-25T13:57:55.820641Z","shell.execute_reply.started":"2021-09-25T13:50:31.568221Z","shell.execute_reply":"2021-09-25T13:57:55.819950Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}